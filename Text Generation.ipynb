{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text with LSTM neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code is adapted from the github page\n",
    "\n",
    "https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original description from author's code:\n",
    "\n",
    "Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus has at least ~100k characters. ~1M is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Amazon product reviews as the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Just another flavor of Kit Kat but the taste i...\n",
       "1    I bought this on impulse and it comes from Jap...\n",
       "2    Really good. Great gift for any fan of green t...\n",
       "3    I had never had it before, was curious to see ...\n",
       "4    I've been looking forward to trying these afte...\n",
       "5    These Kit-kats are very good, but if you're lo...\n",
       "6    I found these in a Mitsuwa Marketplace in Illi...\n",
       "7    Creamy white chocolate infused with Matcha gre...\n",
       "8    After hearing mixed opinions about these Kit K...\n",
       "9    I love green tea, I love Kit Kats, but the two...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset of Amazon product reviews\n",
    "data = pd.read_csv(\"reviews.csv\",names=[\"review\"])\n",
    "data.review[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in text: 494448\n"
     ]
    }
   ],
   "source": [
    "#Limit the number of records for now\n",
    "data = data.iloc[:1000,:]\n",
    "data = data.review.apply(lambda x: str(x).lower())\n",
    "\n",
    "text = \" \".join(list(data))\n",
    "\n",
    "#Remove HTML tags and other nuisances \n",
    "regex_to_remove = [r'<a href=.* </a>',r'[^\\x00-\\x7F]+']\n",
    "for regex in regex_to_remove:\n",
    "    text = re.sub(regex,\"\",text)\n",
    "\n",
    "#Remove character strings that are rare\n",
    "chars_to_remove = ['*','<','=','>','@','[',']','_','}','~','br /',\"'\",'+','#','`','{']\n",
    "for bad_char in chars_to_remove:\n",
    "    text = text.replace(bad_char,\"\")\n",
    "    \n",
    "#Make all spaces single-spaced and eliminate multiple ! and ? characters\n",
    "text = re.sub(\" +\",\" \",text)\n",
    "text = re.sub(\"(\\\\?!)+\",\"?!\",text)\n",
    "text = re.sub(\"(!\\\\?)+\",\"!?\",text)\n",
    "text = re.sub(\"!+\",\"!\",text)\n",
    "text = re.sub(\"\\\\?+\",\"?\",text)\n",
    "\n",
    "print('Number of characters in text:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mappings between characters and thier indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique characters: 53\n"
     ]
    }
   ],
   "source": [
    "#Determine the number of unique characters and create mappings for vectorization\n",
    "chars = sorted(list(set(text)))\n",
    "print('Total unique characters:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break the text into sequences (\"sentences\") and set aside the next character as predictor target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 494388\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat the sequences and targets as a matrix and vector\n",
    "##### The character mapping provides a method to one-hot-encode each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences are now 2D arrays\n"
     ]
    }
   ],
   "source": [
    "#Convert the character sequences into 2D arrays using the mapping dictionaries from above\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "print(\"Sequences are now 2D arrays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile the LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Introduction_to_NLP/Images/LSTM.png\" title=\"LSTM Neural Network Node\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "#Build an LSTM model\n",
    "node_size = len(chars)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(node_size,input_shape=(maxlen,node_size)))\n",
    "#model.add(LSTM(node_size))\n",
    "model.add(Dense(node_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "print('Model compiled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to sample a probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generalization of softmax function with temperature parameter\n",
    "#     High temperature \"flattens\" the distribution and, to a degree, equalizes the probabilities, while low \n",
    "#     temperature accentuates already likely probabilities\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    #multinomial(n - number of samples,\n",
    "    #            pvals - probability of each value,\n",
    "    #            size - number of such experiments to conduct)\n",
    "    #e.g. Roll three dice and do it again: multinomial(3,[1/6.]*6,2)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model and generate some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "494388/494388 [==============================] - 361s 731us/step - loss: 1.5736\n",
      "Epoch 2/5\n",
      "494388/494388 [==============================] - 386s 780us/step - loss: 1.5705\n",
      "Epoch 3/5\n",
      "494388/494388 [==============================] - 367s 742us/step - loss: 1.5669\n",
      "Epoch 4/5\n",
      "494388/494388 [==============================] - 366s 740us/step - loss: 1.5644\n",
      "Epoch 5/5\n",
      "494388/494388 [==============================] - 362s 733us/step - loss: 1.5621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efce01b35f8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with the processed text corpus data\n",
    "epochs = 5\n",
    "batchSize = 128\n",
    "\n",
    "model.fit(X, y, batch_size=batchSize, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some text with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with seed: \"nic.simply organic is a brand i use a lot for extracts, and \"\n",
      "\n",
      "----- \n",
      "\n",
      "nic.simply organic is a brand i use a lot for extracts, and the taste for the good the sauce stores the coffee i have a blue in the stuff and it is an item it tea we was to me, and a for the based this seastant the like this is this as a because this water with the syrup in the because the sugar comeration and someal perfect to me and all and pastive and so i sauce the great version out to could not in for the store. this is the make shipping loves an an a"
     ]
    }
   ],
   "source": [
    "temperature = .5\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "#start_index = 245430\n",
    "\n",
    "generated = ''\n",
    "sequence = text[start_index: start_index + maxlen]\n",
    "#sequence = text[:maxlen]\n",
    "generated += sequence\n",
    "\n",
    "print('Generating with seed: \"{}\"'.format(sequence))\n",
    "print('\\n----- \\n')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "for _ in range(400):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sequence = sequence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
