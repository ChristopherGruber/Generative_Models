{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text with LSTM neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code is adapted from the github page\n",
    "\n",
    "https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original description from author's code:\n",
    "\n",
    "Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus has at least ~100k characters. ~1M is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Amazon product reviews as the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Just another flavor of Kit Kat but the taste i...\n",
       "1    I bought this on impulse and it comes from Jap...\n",
       "2    Really good. Great gift for any fan of green t...\n",
       "3    I had never had it before, was curious to see ...\n",
       "4    I've been looking forward to trying these afte...\n",
       "5    These Kit-kats are very good, but if you're lo...\n",
       "6    I found these in a Mitsuwa Marketplace in Illi...\n",
       "7    Creamy white chocolate infused with Matcha gre...\n",
       "8    After hearing mixed opinions about these Kit K...\n",
       "9    I love green tea, I love Kit Kats, but the two...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset of Amazon product reviews\n",
    "data = pd.read_csv(\"reviews.csv\",names=[\"review\"])\n",
    "data.review[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in text: 494448\n"
     ]
    }
   ],
   "source": [
    "#Limit the number of records for now\n",
    "data = data.iloc[:1000,:]\n",
    "data = data.review.apply(lambda x: str(x).lower())\n",
    "\n",
    "text = \" \".join(list(data))\n",
    "\n",
    "#Remove HTML tags and other nuisances \n",
    "regex_to_remove = [r'<a href=.* </a>',r'[^\\x00-\\x7F]+']\n",
    "for regex in regex_to_remove:\n",
    "    text = re.sub(regex,\"\",text)\n",
    "\n",
    "#Remove character strings that are rare\n",
    "chars_to_remove = ['*','<','=','>','@','[',']','_','}','~','br /',\"'\",'+','#','`','{']\n",
    "for bad_char in chars_to_remove:\n",
    "    text = text.replace(bad_char,\"\")\n",
    "    \n",
    "#Make all spaces single-spaced and eliminate multiple ! and ? characters\n",
    "text = re.sub(\" +\",\" \",text)\n",
    "text = re.sub(\"(\\\\?!)+\",\"?!\",text)\n",
    "text = re.sub(\"(!\\\\?)+\",\"!?\",text)\n",
    "text = re.sub(\"!+\",\"!\",text)\n",
    "text = re.sub(\"\\\\?+\",\"?\",text)\n",
    "\n",
    "print('Number of characters in text:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mappings between characters and thier indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique characters: 53\n"
     ]
    }
   ],
   "source": [
    "#Determine the number of unique characters and create mappings for vectorization\n",
    "chars = sorted(list(set(text)))\n",
    "print('Total unique characters:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break the text into sequences (\"sentences\") and set aside the next character as predictor target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 494388\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat the sequences and targets as a matrix and vector\n",
    "##### The character mapping provides a method to one-hot-encode each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences are now 2D arrays\n"
     ]
    }
   ],
   "source": [
    "#Convert the character sequences into 2D arrays using the mapping dictionaries from above\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "print(\"Sequences are now 2D arrays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile the LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Introduction_to_NLP/Images/LSTM.png\" title=\"LSTM Neural Network Node\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "#Build an LSTM model\n",
    "nodeSize = len(chars)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(nodeSize, input_shape=(maxlen, len(chars))))\n",
    "#model.add(LSTM(nodeSize, input_shape=(maxlen, len(chars)),return_sequences=True))\n",
    "#model.add(LSTM(nodeSize))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "print('Model compiled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to sample a probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generalization of softmax function with temperature parameter\n",
    "#     High temperature \"flattens\" the distribution and, to a degree, equalizes the probabilities, while low temperature\n",
    "#     accentuates already likely probabilities\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    #multinomial(n - number of samples,\n",
    "    #            pvals - probability of each value,\n",
    "    #            size - number of such experiments to conduct)\n",
    "    #e.g. Roll three dice and do it again: multinomial(3,[1/6.]*6,2)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model and generate some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "494388/494388 [==============================] - 337s 681us/step - loss: 1.4884\n",
      "Epoch 2/20\n",
      "209920/494388 [===========>..................] - ETA: 3:02 - loss: 1.4827"
     ]
    }
   ],
   "source": [
    "#Fit the model with the processed text corpus data\n",
    "epochs = 20\n",
    "batchSize = 1024\n",
    "\n",
    "model.fit(X, y, batch_size=batchSize, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some text with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with seed: \"y makes a big difference--i especially like brown rice and o\"\n",
      "\n",
      "----- \n",
      "\n",
      "y makes a big difference--i especially like brown rice and one to the beans and the best to the best the stuff is a store and the stuff is a spicy and the product is a delicious and the best the coffee so i do not a stock and the stuff is a special and the stuff is a good and the stuff is a store to the best the stuff is a store and the better than the stuff is a little a store and the best and the stuff is a store and the stuff is a store and the best and"
     ]
    }
   ],
   "source": [
    "diversity = 0.1\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "#start_index = 245430\n",
    "\n",
    "generated = ''\n",
    "sequence = text[start_index: start_index + maxlen]\n",
    "#sequence = text[:maxlen]\n",
    "generated += sequence\n",
    "\n",
    "print('Generating with seed: \"{}\"'.format(sequence))\n",
    "print('\\n----- \\n')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "for _ in range(400):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, diversity)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sequence = sequence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
